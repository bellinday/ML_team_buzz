{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a test\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as fn\n",
    "import numpy\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "\n",
    "# steps involved:\n",
    "# 1. Download and define the training, testing data\n",
    "# 2. Define the model by creating neural networks\n",
    "# 3. Calculate the gradient, loss and update the model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "# transformation = torchvision.transforms.ToTensor()\n",
    "transformation = torchvision.transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "# test_transform  = torchvision.transforms.Compose([\n",
    "#     transforms.Resize((784)),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "num_class = 10\n",
    "input_size = 784\n",
    "hidden_size = 100\n",
    "batches = 4\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transformation, download=True)\n",
    "mnist_test = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=transformation, download=False)\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(dataset=mnist_train, batch_size=batches, shuffle=True)\n",
    "test_data = torch.utils.data.DataLoader(dataset=mnist_test, batch_size=batches, shuffle=False)\n",
    "\n",
    "examples = iter(train_data)\n",
    "samples, label = examples.next()\n",
    "print(samples.shape, label.shape)\n",
    "\n",
    "test_examples = iter(test_data)\n",
    "test_samples, test_lables = test_examples.__next__()\n",
    "\n",
    "\n",
    "# for i in range(6):\n",
    "#     plt.subplot(3,3, i+1)\n",
    "#     plt.imshow(samples[i][0], cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.imshow(samples[99][0], cmap='gray')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# 2. Create the neural network layers\n",
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3),\n",
    "            nn.Conv2d(8, 16, 3)\n",
    "            # nn.ReLU(),\n",
    "            # nn.AvgPool2d(2, stride=2),  # (N, 3, 24, 24) -> (N,  3, 12, 12)\n",
    "            # nn.Conv2d(3, 6, 3),\n",
    "            # nn.BatchNorm2d(6)           # (N, 3, 12, 12) -> (N,  6, 10, 10)\n",
    "        )\n",
    "        # self.features1 = nn.Sequential(\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.AvgPool2d(2, stride=2)   # (N, 6, 10, 10) -> (N,  6, 5, 5)\n",
    "        # )\n",
    "        # self.classifier = nn.Sequential(\n",
    "        #     nn.Linear(150, 25),         # (N, 150) -> (N, 25)\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(25,10)            # (N, 25) -> (N, 10)\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        # x = self.features1(x)\n",
    "        # x = x.view(x.size(0), -1)\n",
    "        # x = self.classifier(x)\n",
    "        return x\n",
    "    # def __init__(self, input_size, num_class):\n",
    "    #     super(NeuralNetwork, self).__init__()\n",
    "    #     self.conv1 = nn.Sequential(\n",
    "    #         nn.Conv2d(\n",
    "    #             in_channels=input_size, out_channels=32, kernel_size=(2,2), padding=2\n",
    "    #         ),\n",
    "    #         # nn.ReLU(),\n",
    "    #         # nn.MaxPool2d(kernel_size=2),\n",
    "    #     )\n",
    "    #     self.maxp = nn.MaxPool2d(kernel_size=(2,2))\n",
    "    #     self.conv2 = nn.Sequential(\n",
    "    #         nn.Conv2d(\n",
    "    #             in_channels=32,\n",
    "    #             out_channels=64,\n",
    "    #             kernel_size=(3,3),\n",
    "    #             padding=0,\n",
    "    #             stride=1\n",
    "    #         ),\n",
    "    #         # nn.ReLU(),\n",
    "    #         # nn.MaxPool2d(2),\n",
    "    #     )\n",
    "    #     self.maxp2 = nn.MaxPool2d(kernel_size=(2,2))\n",
    "    #     self.fc1 = nn.Sequential(\n",
    "    #         nn.Linear(in_features=64*5*5, out_features=200)\n",
    "    #     )\n",
    "    #     self.fc2 = nn.Sequential(\n",
    "    #         nn.Linear(in_features=200, out_features=num_class),\n",
    "    #         nn.ReLU()\n",
    "    #     )\n",
    "    #     # fully connected layer, output 10 classes\n",
    "    #     # self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "    #\n",
    "    # def forward(self, x):\n",
    "    #     x = self.conv1(x)\n",
    "    #     x = self.maxp1(x)\n",
    "    #     x = self.conv2(x)\n",
    "    #     x = self.maxp2(x)\n",
    "    #     x = x.contiguous().view(x.size(0), -1)\n",
    "    #     x = self.fc1(x)\n",
    "    #     x = self.fc2(x)\n",
    "    #     return x\n",
    "\n",
    "\n",
    "    # def forward(self, x):\n",
    "    #     x = self.conv1(x)\n",
    "    #     x = self.conv2(x)\n",
    "    #     # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "    #     x = x.view(x.size(0), -1)\n",
    "    #     output = self.out(x)\n",
    "    #     return output\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "output = model(samples)\n",
    "print(output)\n",
    "\n",
    "plt.imshow(output[0, 0, :, :].detach().numpy())\n",
    "plt.show()\n",
    "\n",
    "# 3. Loss and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#\n",
    "# # 4. Training loop\n",
    "# n_steps = len(train_data)\n",
    "# for epoch in range(num_epochs):\n",
    "#     for i, datas in enumerate(samples):\n",
    "# # reshape the images\n",
    "# #         inputs, label = datas\n",
    "# #         inputs, label = datas[0].to(device), datas[1].to(device)\n",
    "# #         samples = np.expand_dims(datas, 1)    # if numpy array\n",
    "# #         images = torch.unsqueeze(datas, 1).to(device)\n",
    "#         # images = images.reshape(-1, 28*28).to(device)\n",
    "#         label = label.to(device)\n",
    "# # forward pass\n",
    "#         outputs = model(samples)\n",
    "#         loss = criterion(outputs, label)\n",
    "#\n",
    "# # backward pass\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#\n",
    "#         if(i+1)%100 ==0 :\n",
    "#             print(f\"epoch {epoch+1} loss = {loss.item()}\")\n",
    "#\n",
    "# # test and evaluate\n",
    "#\n",
    "# with torch.no_grad():\n",
    "#     n_correct = 0\n",
    "#     n_samples = 0\n",
    "#     for images, labels in test_data:\n",
    "#         images = images.reshape(-1, 28*28).to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         outputs = model(images)\n",
    "#\n",
    "# # value, index\n",
    "#         _, predictions = torch.max(outputs, 1)\n",
    "#         n_samples += label.shape[0]\n",
    "#         n_correct = (predictions == labels).sum().item()\n",
    "#\n",
    "#     acc = 100.0* n_correct / n_samples\n",
    "#     print(f\"accuracy = {acc}\")\n",
    "#\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# while True:\n",
    "#     status, photo = cap.read()\n",
    "#     cv2.imshow('Attention please', photo)\n",
    "#     if cv2.waitKey(1) == 13:\n",
    "#         img = cv2.imwrite(\"new.png\", photo)\n",
    "#         break\n",
    "# cv2.destroyAllWindows()\n",
    "#\n",
    "# test_image = test_samples[74][0]\n",
    "# test_image = test_image.reshape(-1, 784).to(device)\n",
    "# # images = torch.from_numpy(test_image)\n",
    "# # width, height = test_image.size\n",
    "# # crop = test_image.resize((784, int(784*(height/width))) if width < height else (int(784*(width/height)), 784))\n",
    "# # crop = fn.center_crop(images, output_size=[28])\n",
    "# # images = torchvision.transforms.CenterCrop(size=784)\n",
    "# # images = images.reshape(-1, 28 * 28).to(device)\n",
    "# # print(type(crop))\n",
    "# # print(crop.shape)\n",
    "# print(model(test_image))\n",
    "# plt.imshow(test_samples[74][0], cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# steps involved:\n",
    "# 1. Download and define the training, testing data\n",
    "# 2. Define the model by creating neural networks\n",
    "# 3. Calculate the gradient, loss and update the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
